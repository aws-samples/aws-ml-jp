{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e1c348b8",
   "metadata": {},
   "source": [
    "# mpt-7b-Instruct を SageMaker で Hosting\n",
    "このノートブックは、mpt-7b を Instruction tuning した mpt-7b-Instruct を、ローカルで推論し、それを SageMaker で Hosting するノートブックです。  \n",
    "モデルの詳細については [Hugging Face mpt-7b-instruct](https://huggingface.co/mosaicml/mpt-7b-instruct) や [MosaicML の blog](https://www.mosaicml.com/blog/mpt-7b) を参照ください。\n",
    "一度ローカルで推論する都合上、ml.g5.2xlarge インスタンスを使用します。  \n",
    "SageMaker Notebooks の `conda_pytorch_p39` カーネルと、SageMaker Studio Notebook の `PyTorch 1.13 Python 3.9 GPU Optimized` カーネルで動いた実績があります。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b950e17",
   "metadata": {},
   "source": [
    "## ローカル推論\n",
    "SageMaker で動かす前にローカルで動作確認を行う。\n",
    "### ローカルで動かすためのライブラリをインストール\n",
    "必要なモジュールをインストールする"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0436c68",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "pip install transformers==4.26 einops sagemaker -U"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a31ac1d-e300-44a3-8d38-f709e7370ad8",
   "metadata": {},
   "source": [
    "### モジュール読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "636d9a5e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import transformers\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import gc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e45fe9a8",
   "metadata": {},
   "source": [
    "### モデルのダウンロード\n",
    "tokenizer と model をダウンロードします。\n",
    "[How to use](https://huggingface.co/mosaicml/mpt-7b-instruct#how-to-use) に沿って実行します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab583c32",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    \"mosaicml/mpt-7b-Instruct\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22afb4a9-2812-4c3a-969d-fe8550b6812e",
   "metadata": {},
   "source": [
    "以下のセルはモデルを DL して読み込むため 8-9 分ほど時間がかかります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e4a1bf",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    \"mosaicml/mpt-7b-Instruct\", \n",
    "    torch_dtype=torch.float16,\n",
    "    trust_remote_code=True\n",
    ").to(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dfbf366",
   "metadata": {},
   "source": [
    "### モデルの保存\n",
    "ローカルで推論する前に、モデルをストレージに出力して、再度読み込みます。  \n",
    "SageMaker で Hosting する際はモデルをファイルから読み込むことが一般的で、ローカルで動かすときもその方法に則って行うと、SageMaker に移植しやすいためにこの手順を入れています。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b916ce42",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!rm -rf './model'\n",
    "!mkdir -p './model/code'\n",
    "model_dir = './model'\n",
    "tokenizer.save_pretrained(model_dir)\n",
    "model.save_pretrained(model_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d8c7555-9718-47d0-acb9-4ace107e27b1",
   "metadata": {},
   "source": [
    "メモリ解放をします(OOM 対策)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce465780",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "del model\n",
    "del tokenizer\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94294834-1f98-4930-8680-bb9bb1bc92b2",
   "metadata": {},
   "source": [
    "### モデルの再ロード\n",
    "ファイルからモデルをロードします。\n",
    "7 分程度かかります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b06c53b3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0363b71d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_dir,\n",
    "    trust_remote_code=True,\n",
    "    torch_dtype=torch.float16,\n",
    ").to(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d5b4301-5647-400c-80c1-602ae19302c6",
   "metadata": {},
   "source": [
    "### 推論する\n",
    "prompt の形式は以下にすると良い結果が得られやすいです。  \n",
    "(Instruction Tuning する際のトレーニングデータの形式に則った方式）\n",
    "```text\n",
    "{状況や前提}\n",
    "### Instruction:\n",
    "{命令文}\n",
    "### Response:\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e3c1a93",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt = '''Python で フィボナッチ数列の 10 番目を知りたいです。\n",
    "### Instruction:\n",
    "フィボナッチ数列を求める関数とその関数の実行コードを記載してください。\n",
    "### Response:'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb28fdbd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "inputs = tokenizer(prompt, return_tensors='pt').to(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ac5909",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "input_length = inputs.input_ids.shape[1]\n",
    "with torch.no_grad():\n",
    "    outputs = model.generate(\n",
    "        **inputs, \n",
    "        max_new_tokens=128, \n",
    "        do_sample=True, \n",
    "        temperature=0.01, \n",
    "        top_p=0.7, \n",
    "        top_k=50, \n",
    "        return_dict_in_generate=True\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1902b2f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 結果を出力する\n",
    "token = outputs.sequences[0, input_length:]\n",
    "output_str = tokenizer.decode(token)\n",
    "output_str = output_str[:output_str.find('<|endoftext|>')]\n",
    "\n",
    "print(output_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33d4a305-e93a-4753-b1e0-edf9576a4e81",
   "metadata": {},
   "source": [
    "出力結果を以下のセルに貼り付けて、コードが実行できるか確認しましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c61ee29b-1018-4109-b996-f2c65575dae9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 出力を以下に貼り付けて実行\n",
    "def fib(n):\n",
    "    if n == 0:\n",
    "        return 0\n",
    "    elif n == 1:\n",
    "        return 1\n",
    "    else:\n",
    "        return fib(n-1) + fib(n-2)\n",
    "\n",
    "print(fib(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cb081d3-3f9f-4abd-8a57-da0bcdfd669f",
   "metadata": {},
   "source": [
    "無事動いたらローカルでやっていたことを SageMaker の Hosting を使って再現します。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67269333",
   "metadata": {},
   "source": [
    "## SageMaker による推論\n",
    "\n",
    "### モジュールのロードと定数の設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06d30e39",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "import boto3\n",
    "sm = boto3.client('sagemaker')\n",
    "role = sagemaker.get_execution_role()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67ed6305",
   "metadata": {},
   "source": [
    "### 推論コードの作成\n",
    "先程実行したコードをもとに記述していきます。  \n",
    "まずは必要なモジュールを記述した requirements.txt を用意します。  \n",
    "今回は [deep-learning-containers](https://github.com/aws/deep-learning-containers)の HuggingFace のコンテナを使います。  \n",
    "einops だけ不足しているので requirements.txt に記載します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26fdc6ac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%writefile model/code/requirements.txt\n",
    "einops"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aae3d83-b4c9-4b2b-a1d5-9fba9a35c93b",
   "metadata": {},
   "source": [
    "先程実行したコードを SageMaker Inference 向けに改変します。\n",
    "1. `model_fn` でモデルを読み込みます。先程は huggingface のモデルを直接ロードしましたが、`model_dir` に展開されたモデルを読み込みます。\n",
    "2. `input_fn` で前処理を行います。\n",
    "    * json 形式のみを受け付け他の形式は弾くようにします。\n",
    "    * json 文字列を dict 形式に変換して `return` します。\n",
    "3. `predict_fn` で推論します。`temperature` などのパラメータも合わせて入力します。\n",
    "4. `output_fn` で json 形式にして `return` します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fbc4cf4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%writefile model/code/inference.py\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import json\n",
    "\n",
    "def model_fn(model_dir):\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_dir)\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        model_dir,\n",
    "        trust_remote_code=True,\n",
    "        torch_dtype=torch.float16,\n",
    "    ).to(\"cuda:0\")\n",
    "    return {'tokenizer':tokenizer,'model':model}\n",
    "\n",
    "def input_fn(data, content_type):\n",
    "    if content_type == 'application/json':\n",
    "        data = json.loads(data)\n",
    "    else:\n",
    "        raise TypeError('content_type is only allowed application/json')\n",
    "    return data\n",
    "\n",
    "def predict_fn(data, model):\n",
    "    inputs = model['tokenizer'](data['prompt'], return_tensors='pt').to(\"cuda:0\")\n",
    "    input_length = inputs.input_ids.shape[1]\n",
    "    max_new_tokens = data['max_new_tokens']\n",
    "    do_sample = data['do_sample']\n",
    "    temperature = data['temperature']\n",
    "    top_p = data['top_p']\n",
    "    top_k = data['top_k']\n",
    "    return_dict_in_generate = data['return_dict_in_generate']\n",
    "    with torch.no_grad():\n",
    "        outputs = model['model'].generate(\n",
    "            **inputs, \n",
    "            max_new_tokens=max_new_tokens, \n",
    "            do_sample=do_sample, \n",
    "            temperature=temperature, \n",
    "            top_p=top_p, \n",
    "            top_k=top_k, \n",
    "            return_dict_in_generate=return_dict_in_generate\n",
    "        )\n",
    "    \n",
    "    token = outputs.sequences[0, input_length:]\n",
    "    output_str = model['tokenizer'].decode(token)\n",
    "    \n",
    "    return output_str\n",
    "\n",
    "def output_fn(data, accept_type):\n",
    "    if accept_type == 'application/json':\n",
    "        data = json.dumps({'result' : data})\n",
    "    else:\n",
    "        raise TypeError('content_type is only allowed application/json')\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54a1a2d0",
   "metadata": {},
   "source": [
    "### モデルアーティファクトの作成と S3 アップロード\n",
    "アーティファクト(推論コード + モデル)を tar.gz に固めます。時間がかかるので `pigz` で並列処理を行います。  \n",
    "ml.g5.2xlarge で 3-4 分ほどかかります。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c89a3a6-804d-4512-81f5-64a0bbfee47c",
   "metadata": {
    "tags": []
   },
   "source": [
    "※ SageMaker Studio を使っている場合は pigz が入っていないので、以下セルのコメントを解除してインストールしてください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1200c53-ff5d-4b12-b7e5-8303a22f0680",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !apt update -y\n",
    "# !apt install pigz -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b003b0fd",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "!rm model.tar.gz\n",
    "%cd model/\n",
    "!tar  cv ./ | pigz -p 8 > ../model.tar.gz # 8 並列でアーカイブ\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a5f9124-a8d9-4460-a7f5-c350b8d05629",
   "metadata": {},
   "source": [
    "S3 にアップロードします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87e9a3a0",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "model_s3_uri = sagemaker.session.Session().upload_data(\n",
    "    'model.tar.gz',\n",
    "    key_prefix='mpt-7b-Instruct'\n",
    ")\n",
    "print(model_s3_uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "489d0ab5",
   "metadata": {},
   "source": [
    "### SageMaker SDK を用いてデプロイ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7866334",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.huggingface import HuggingFaceModel\n",
    "from sagemaker.serializers import JSONSerializer\n",
    "from sagemaker.deserializers import JSONDeserializer\n",
    "region = boto3.session.Session().region_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdfe392f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 名前の設定\n",
    "model_name = 'mpt-7b-Instruct'\n",
    "endpoint_config_name = model_name + 'Config'\n",
    "endpoint_name = model_name + 'Endpoint'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "440e5c49",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "image_uri = sagemaker.image_uris.retrieve(\n",
    "    framework='huggingface',\n",
    "    region=region,\n",
    "    version='4.26',\n",
    "    image_scope='inference',\n",
    "    base_framework_version='pytorch1.13',\n",
    "    instance_type = 'ml.g5.xlarge'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68d03094",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "huggingface_model = HuggingFaceModel(\n",
    "    model_data = model_s3_uri,\n",
    "    role = role,\n",
    "    image_uri = image_uri\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a98cf65",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "predictor = huggingface_model.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type='ml.g5.2xlarge',\n",
    "    endpoint_name=endpoint_name,\n",
    "    serializer=JSONSerializer(),\n",
    "    deserializer=JSONDeserializer()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4fccf8b",
   "metadata": {},
   "source": [
    "### SageMaker SDK で推論\n",
    "model_fn の実行に時間がかかってしまい、エンドポイントが IN_SERVICE になっても、初回推論はしばらく動かないことがあります。  \n",
    "CloudWatch Logs に以下のような表示がある場合はしばらく待てば使えるようになります。  \n",
    "`[WARN] pool-3-thread-1 com.amazonaws.ml.mms.metrics.MetricCollector - worker pid is not available yet.`  \n",
    "だいたい 6 分くらいかかるため、リトライを入れています。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8863211d-6b60-4c2a-bed7-2bb306f37d32",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# prompt 確認\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e7e3b3e",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from time import sleep\n",
    "request = {\n",
    "    'prompt' : prompt,\n",
    "    'max_new_tokens' : 128,\n",
    "    'do_sample' : True,\n",
    "    'temperature' : 0.01,\n",
    "    'top_p' : 0.7,\n",
    "    'top_k' : 50,\n",
    "    'return_dict_in_generate' : True\n",
    "}\n",
    "\n",
    "for i in range(10):\n",
    "    try:\n",
    "        output_str = predictor.predict(request)['result']\n",
    "        break\n",
    "    except:\n",
    "        sleep(60)\n",
    "\n",
    "print(output_str[:output_str.find('<|endoftext|>')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f85c17da",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "predictor.delete_model()\n",
    "predictor.delete_endpoint()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7896098a",
   "metadata": {},
   "source": [
    "## boto3 でデプロイと推論\n",
    "標準だと SageMaker SDK が入っていない環境からデプロイや推論する場合(例:AWS Lambda など)は、boto3 でデプロイや推論することも多いです。  \n",
    "以下のセルは boto3 で実行する方法を記述しています。\n",
    "各 API の詳細は Document を確認してください。\n",
    "[SageMaker](https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/sagemaker.html)  \n",
    "[SageMakerRuntime](https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/sagemaker-runtime.html)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7ec9d81",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "sm = boto3.client('sagemaker')\n",
    "smr = boto3.client('sagemaker-runtime')\n",
    "endpoint_inservice_waiter = sm.get_waiter('endpoint_in_service')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc667c06-cf76-4076-808d-5105389a7740",
   "metadata": {},
   "source": [
    "モデルの作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6754ae19",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "response = sm.create_model(\n",
    "    ModelName=model_name,\n",
    "    PrimaryContainer={\n",
    "        'Image': image_uri,\n",
    "        'ModelDataUrl': model_s3_uri,\n",
    "        'Environment': {\n",
    "            'SAGEMAKER_CONTAINER_LOG_LEVEL': '20',\n",
    "            'SAGEMAKER_REGION': region,\n",
    "        }\n",
    "    },\n",
    "    ExecutionRoleArn=role,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "819e4d68-56a0-440c-bce0-65c61f2f364d",
   "metadata": {
    "tags": []
   },
   "source": [
    "エンドポイントコンフィグの作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a118dc38",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "response = sm.create_endpoint_config(\n",
    "    EndpointConfigName=endpoint_config_name,\n",
    "    ProductionVariants=[\n",
    "        {\n",
    "            'VariantName': 'AllTrafic',\n",
    "            'ModelName': model_name,\n",
    "            'InitialInstanceCount': 1,\n",
    "            'InstanceType': 'ml.g5.2xlarge',\n",
    "        },\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4d159b7-b6ca-401e-82f5-0682a597d162",
   "metadata": {},
   "source": [
    "エンドポイントの作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e39686d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "response = sm.create_endpoint(\n",
    "    EndpointName=endpoint_name,\n",
    "    EndpointConfigName=endpoint_config_name,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca0d90ef-31e6-4639-896c-8cf8a22d3951",
   "metadata": {},
   "source": [
    "エンドポイント作成の完了を待つ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fe7b8ac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "endpoint_inservice_waiter.wait(\n",
    "    EndpointName=endpoint_name,\n",
    "    WaiterConfig={'Delay': 5,}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2017ad04-23c8-4259-83a6-4812b3784291",
   "metadata": {},
   "source": [
    "推論を行います。  \n",
    "ただし初回推論時のみモデルのロードに 7 分ほどかかるため、先程同様リトライを入れています。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e6b059d-89d1-45c0-819a-e7f3b412e74a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# prompt 確認\n",
    "print(request)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69159367",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# 推論\n",
    "smr = boto3.client('sagemaker-runtime')\n",
    "\n",
    "for i in range(10):\n",
    "    try:\n",
    "        response = smr.invoke_endpoint(\n",
    "            EndpointName=endpoint_name,\n",
    "            ContentType='application/json',\n",
    "            Accept='application/json',\n",
    "            Body=json.dumps(request)\n",
    "        )\n",
    "        break\n",
    "    except:\n",
    "        sleep(60)\n",
    "output_str = json.loads(response['Body'].read().decode('utf-8'))['result']\n",
    "print(output_str[:output_str.find('<|endoftext|>')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48b9ddce-5b24-4878-ba9b-efa6ce76a2cd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "response = smr.invoke_endpoint(\n",
    "        EndpointName=endpoint_name,\n",
    "        ContentType='application/json',\n",
    "        Accept='application/json',\n",
    "        Body=json.dumps(request)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cf1199f-f812-46f5-8b2d-423f0e9b6ece",
   "metadata": {},
   "source": [
    "お片付け"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b036b51",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sm.delete_endpoint(EndpointName=endpoint_name)\n",
    "sm.delete_endpoint_config(EndpointConfigName=endpoint_config_name)\n",
    "sm.delete_model(ModelName=model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34d781e1-e2f1-41c8-83a6-59608b133c08",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   }
  ],
  "instance_type": "ml.g5.2xlarge",
  "kernelspec": {
   "display_name": "Python 3 (PyTorch 1.13 Python 3.9 GPU Optimized)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/pytorch-1.13-gpu-py39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
