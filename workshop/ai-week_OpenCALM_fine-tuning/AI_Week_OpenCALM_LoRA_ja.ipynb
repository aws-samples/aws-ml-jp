{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9b262721-9ba7-40c2-acc4-96c41cf9230a",
   "metadata": {},
   "source": [
    "# AWS AI Week : OpenCALM SageMaker Fine-tuning\n",
    "\n",
    "SageMaker上でLoRAにより [OpenCALM](https://huggingface.co/cyberagent/open-calm-7b) を Fine-tuning し、デプロイするサンプルコードです。\n",
    "- このデモでは、Instruction tuning 形式で Fine-tuning を行います。\n",
    "- [JAQKET](https://www.nlp.ecei.tohoku.ac.jp/projects/jaqket/) データセットを使用しています。\n",
    "\n",
    "- 以下のようなユースケースを想定しています。\n",
    "  - 日本語対応の大規模言語モデルを使いたい。\n",
    "  - 効率よくInstruction tuning を行い、QA の仕方を学習させる。\n",
    "\n",
    "SageMaker Studio のノートブックカーネルは、 Data Science 2.0、Python 3 で動作確認済みです。\n",
    "\n",
    "---\n",
    "\n",
    "まず、必要なパッケージをインストールしてアップグレードします。以下のセルを初回に実行したら、カーネルを再起動します。\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32904a97-bedb-451a-b2cc-ac691f7708de",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install -U \"sagemaker>=2.143.0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2edc8a17-9a6b-4dd6-823e-878f6b950ea2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sagemaker, boto3, json\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.pytorch.model import PyTorchModel\n",
    "from sagemaker.huggingface import HuggingFace\n",
    "\n",
    "role = get_execution_role()\n",
    "region = boto3.Session().region_name\n",
    "sess = sagemaker.Session()\n",
    "bucket = sess.default_bucket()\n",
    "\n",
    "sagemaker.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc1b5fe7-9ed9-4d24-b344-a40a781a24a1",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 学習用データセットの準備\n",
    "---\n",
    "Fine-Tuning 用の日本語データをダウンロードします。\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "007e1bb9-2028-4abb-8db2-2b3128971657",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!wget -P data https://jaqket.s3.ap-northeast-1.amazonaws.com/data/aio_02/aio_02_train.jsonl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9f91d9d-ca39-4561-9f89-097a76c40b66",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!head -n 2 data/aio_02_train.jsonl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c26b4e2-86c2-4cac-846a-84e83c9b7253",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Convet .jsonl to .json\n",
    "import pandas as pd\n",
    "\n",
    "# 各行を１レコードとして読み込み、列名を question -> instruction, answers -> output にリネームする。\n",
    "df = pd.read_json(\"data/aio_02_train.jsonl\", orient=\"records\", lines=True)\n",
    "df = df.rename(columns={\"question\": \"instruction\", \"answers\": \"output\"})\n",
    "df = df[[\"instruction\", \"output\"]]\n",
    "df[\"output\"] = df[\"output\"].apply(lambda x: f\"{x[0]}」\")\n",
    "df[\"input\"] = \"\"\n",
    "print(df.shape)\n",
    "df.to_json(\n",
    "    \"data/aio_02_train_formatted.jsonl\", orient=\"records\", force_ascii=False, lines=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9e4e738-2983-40b2-b536-a0d9e26abd7a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22dd631f-5d99-42fd-b944-6210d574440a",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "データセットを先頭の1,000件のみ取り出します。\n",
    "\n",
    "- 以下を実行したら、直接作成した json ファイルの内容も確認してみてください。\n",
    "- 元データ (aio_02_train_formatted.jsonl)、および、作成済みデータ (aio_02_train_formatted_1000.jsonl) は、「data」フォルダに格納されます。\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56a10d5f-733e-4505-8224-1cd622f8a4fc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 1000 行のデータを取り出す。\n",
    "df_1000 = df.iloc[:1000]\n",
    "df_1000.to_json(\"data/aio_02_train_formatted_1000.jsonl\", orient=\"records\", force_ascii=False, lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbcaf3dd-e6f4-42cd-b072-2844a2e38f82",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(df_1000.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00b791bb-c8a6-4407-8200-d2ebb42dedf2",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "データセットをS3へアップロードします。\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2839074-202c-400d-ae9f-df17eb05e59d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 学習させるデータを指定してS3へアップロード\n",
    "train_jsonpath = \"./data/aio_02_train_formatted_1000.jsonl\"\n",
    "\n",
    "input_train = sess.upload_data(\n",
    "    path=train_jsonpath, key_prefix=\"OpenCALM\"\n",
    ")\n",
    "input_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07b5098b-1ea9-4b85-88ee-9297d5e00c09",
   "metadata": {},
   "source": [
    "## Fine-tuning を実行\n",
    "---\n",
    "作成したデータセットを使用して、Fine-tuning を行います。\n",
    "\n",
    "今回は、[HuggingFace estimator](https://sagemaker.readthedocs.io/en/stable/frameworks/huggingface/sagemaker.huggingface.html#hugging-face-estimator) (推定器) を使用して、学習を行います。\n",
    "\n",
    "- entry_point : 学習のエントリポイントとして実行する Python ソースファイルへのパス(source＿dir)\n",
    "- instance_type : 学習で使用するインスタンスタイプを指定\n",
    "\n",
    "主なハイパーパラメータを説明します。\n",
    "- base_model : Fine-tuning に使用するモデルを指定\n",
    "- data_path : Fine-tuning に使用するデータを指定\n",
    "- num_epochs : 1 epochは、データセット全体が1回だけ渡される(小さなバッチに分割して送信される)\n",
    "- LoRA (Low Rank Adapter)\n",
    "  凍結した事前学習済みモデルに低ランク行列を追加し、低ランク行列に対してパラメータ更新する手法。\n",
    "  - lora_target_modules : チューニング用のパラメーターを用意する\n",
    "  - lora_r : LoRA の行列ランクであり、小さいほど学習によって更新されるパラメータは少なくなる。\n",
    "- prompt_template_name : プロンプトのテンプレートを指定(scripts/code/templates/)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b22bf3b9-e61a-4bdd-b591-bc83e2a4ee07",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "jsonfile = train_jsonpath.split(\"/\")[-1]\n",
    "data_path = \"/opt/ml/input/data/train/\" + jsonfile\n",
    "\n",
    "base_model_name = \"open-calm-7b\"\n",
    "base_model = \"cyberagent/open-calm-7b\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cb98557-3a3f-40ef-baf3-538c4ee4aa8a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "hyperparameters={\n",
    "    'base_model': base_model, # OpenCALM 7B モデルを使用\n",
    "    # 'load_in_8bit': True,\n",
    "    'load_in_4bit': True,\n",
    "    'pad_token_id': 1,\n",
    "    'data_path': data_path, # 要素を調整したデータセットを指定\n",
    "    'num_epochs': 1, # default 3\n",
    "    'cutoff_len': 512,\n",
    "    'group_by_length': False,\n",
    "    'output_dir': '/opt/ml/model',\n",
    "    # 'resume_from_checkpoint': '/opt/ml/checkpoints',\n",
    "    'lora_target_modules': '[query_key_value]',\n",
    "    'lora_r': 16,\n",
    "    'batch_size': 32,\n",
    "    'micro_batch_size': 4,\n",
    "    'prompt_template_name': 'simple_qa_ja',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4a8d836-d44f-4bdc-8d87-cff90f9f6ea7",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "huggingface_estimator = HuggingFace(\n",
    "    base_job_name = base_model_name,\n",
    "    role=role,\n",
    "    entry_point='finetune_ai-week.py',\n",
    "    source_dir='./scripts/code',\n",
    "    # instance_type='ml.g5.2xlarge',\n",
    "    instance_type='ml.p3.2xlarge', # 試験的な実施のため、小さい GPU インスタンスに変更\n",
    "    instance_count=1,\n",
    "    volume_size=200,\n",
    "    transformers_version='4.26',\n",
    "    pytorch_version='1.13',\n",
    "    py_version='py39',\n",
    "    use_spot_instances=False,\n",
    "    # use_spot_instances=True, # スポットインスタンスを利用する場合は True にし、max_wait を有効にする。\n",
    "    # max_wait=86400,\n",
    "    hyperparameters=hyperparameters,\n",
    "    metric_definitions=[{'Name': 'eval_loss', 'Regex': \"'eval_loss': (\\d\\.\\d+)\"},\n",
    "                        {'Name': 'train_loss', 'Regex': \"'loss': (\\d\\.\\d+)\"}],\n",
    "    # checkpoint_s3_uri=f\"s3://{bucket}/{base_job_name}/checkpoint/\",\n",
    ")\n",
    "huggingface_estimator.fit({'train': input_train})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8df141b-86f8-4eff-8ba5-129b78d3efd4",
   "metadata": {
    "tags": []
   },
   "source": [
    "## トレーニングされたモデルを取得\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a02eb6aa-b4c3-4d60-a3fc-94f394df7ac1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "\n",
    "# 最後に実行されたトレーニングジョブで出力されたアーティファクトを取得して S3 に保存\n",
    "def get_latest_training_job_artifact(base_job_name):\n",
    "    sagemaker_client = boto3.client('sagemaker')\n",
    "    response = sagemaker_client.list_training_jobs(NameContains=base_job_name, SortBy='CreationTime', SortOrder='Descending')\n",
    "    training_job_arn = response['TrainingJobSummaries'][0]['TrainingJobArn']\n",
    "    training_job_description = sagemaker_client.describe_training_job(TrainingJobName=training_job_arn.split('/')[-1])\n",
    "    return training_job_description['ModelArtifacts']['S3ModelArtifacts']\n",
    "\n",
    "try:\n",
    "    model_data = huggingface_estimator.model_data\n",
    "except:\n",
    "    # カーネルがリスタートした時にアーティファクトの　URL を取得\n",
    "    model_data = get_latest_training_job_artifact('OpenCALM')\n",
    "    \n",
    "!aws s3 cp {model_data} opencalm.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e23bbc7-6038-4dfd-a632-21b38be59e78",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!rm -rf scripts/model && mkdir scripts/model\n",
    "!tar -xvf opencalm.tar.gz -C scripts/model --no-same-owner --wildcards adapter_*\n",
    "!ls -l scripts/model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44bf1cde-57d4-43f6-be6b-b09bd942219f",
   "metadata": {},
   "source": [
    "## モデルをパッケージして S3 へアップロード\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "916cee87-d530-4e67-8fa6-18550ff92532",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "%cd scripts\n",
    "!tar -czvf ../package.tar.gz *\n",
    "%cd -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e252d1ba-c402-4352-a0f5-c59dc51d6fc9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_path = sess.upload_data('package.tar.gz', bucket=bucket, key_prefix=f\"OpenCALM\")\n",
    "model_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cee0a96e-b185-4e2f-a8dd-75cbb086abfa",
   "metadata": {},
   "source": [
    "## パッケージ化された Fine-tuning 済みのモデルをデプロイする\n",
    "---\n",
    "リアルタイムエンドポイントを作成し、エンドポイント経由で推論できるようにデプロイします。\n",
    "\n",
    "[リアルタイム推論](https://docs.aws.amazon.com/ja_jp/sagemaker/latest/dg/realtime-endpoints.html)は、リアルタイム、インタラクティブ、ミリ秒オーダーの低レイテンシーが要求されるワークロードに最適です。ペイロードサイズは最大 6 MB です。\n",
    "\n",
    "デプロイオプションとして、[非同期推論 (async inference)](https://docs.aws.amazon.com/ja_jp/sagemaker/latest/dg/async-inference.html) を行うこともできます。\n",
    "\n",
    "非同期推論もエンドポイント経由でモデルへアクセスしますが、リクエストをキューに配置して非同期で処理します。ペイロードサイズがリアルタイム推論よりも大きい(最大 1 GB )、処理時間が長い(最大 1 時間)、ほぼリアルタイムの要求に最適です。処理するリクエストがない場合は、オートスケーリングで最少インスタンス数をゼロにすることができるため、コストを節約する事ができます。\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8232665-f10e-4a74-84d6-d5c87640d1f2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.async_inference import AsyncInferenceConfig\n",
    "from sagemaker.serializers import JSONSerializer\n",
    "\n",
    "\n",
    "huggingface_model = PyTorchModel(\n",
    "    model_data=model_path,\n",
    "    framework_version=\"1.13\",\n",
    "    py_version='py39',\n",
    "    role=role,\n",
    "    name=base_model_name,\n",
    "    env={\n",
    "        \"model_params\": json.dumps({\n",
    "            \"base_model\": base_model, # モデルを指定\n",
    "            \"lora_weights\": \"model\", # モデルパッケージを取得するためのパス\n",
    "            \"peft\": True,\n",
    "            \"load_4bit\": True,\n",
    "            \"prompt_template\": \"simple_qa_ja\",\n",
    "        }),\n",
    "        \"SAGEMAKER_MODEL_SERVER_TIMEOUT\": \"3600\"\n",
    "    }\n",
    ")\n",
    "\n",
    "# SageMaker 推論として、モデルをデプロイする\n",
    "predictor = huggingface_model.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type='ml.g5.2xlarge',\n",
    "    endpoint_name=base_model_name,\n",
    "    serializer=JSONSerializer(),\n",
    "    # 非同期推論の場合は、以下オプションを使用する\n",
    "    # async_inference_config=AsyncInferenceConfig()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb4f6d9f-666d-40d6-b2c3-93ec553dded1",
   "metadata": {},
   "source": [
    "## 推論を実行\n",
    "---\n",
    "実際に推論を行なってみます。\n",
    "\n",
    "今回は、クイズ形式のデータセットで Instruction tuning を行ったため、単語で答えられる質問を行います。\n",
    "instruction を変更し、様々な入力を試してください。\n",
    "- max_new_tokens: モデルは、出力長 (入力コンテキストの長さを除く) が max_new_tokens に達するまでテキストを生成する。指定する場合は正の整数でなければならない。\n",
    "- temperature: 出力のランダム性を制御する。temperature が高いと確率の低い単語での出力になり(より創造的)、temperature が低いと確率の高いワードで出力される。\n",
    "- top_p: テキスト生成の各ステップで、累積確率が top_p をもつ最小の単語セットからサンプリングする。(0.1の場合は、確率が上位10%を考慮。) 値は、0〜1 の浮動小数点数。\n",
    "- return_full_text: True の場合、入力テキストが出力テキストの一部として出力される。\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c7c7ff4-74bb-42a4-bf96-c1e14b1af1e2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# With SageMaker SDK\n",
    "\n",
    "from sagemaker.predictor import Predictor\n",
    "from sagemaker.predictor_async import AsyncPredictor\n",
    "from sagemaker.serializers import JSONSerializer\n",
    "from sagemaker.deserializers import JSONDeserializer\n",
    "\n",
    "predictor_client = Predictor(\n",
    "    endpoint_name=base_model_name,\n",
    "    sagemaker_session=sess,\n",
    "    serializer=JSONSerializer(),\n",
    "    deserializer=JSONDeserializer()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09b584fd-9b18-43c8-aed5-7b80abeb478b",
   "metadata": {},
   "source": [
    "- インプット例 ：\n",
    "\n",
    "  - Q：代表的な解熱鎮痛剤のひとつで非ステロイド性抗炎症薬の代名詞とも言うべき医薬品で、ドイツのバイエルが命名し、1899年に商標登録された薬品名は？\n",
    "    - A：アスピリン  \n",
    "  - Q：「充分な説明に基づく合意」を意味する、医療行為を行うにあたって事前に診療の内容を患者に説明し、了承を得ることを英語で何というでしょう?\n",
    "    - A： インフォームドコンセント\n",
    "  - Q：歯磨き粉や日焼け止めクリームなど、医薬品と化粧品の中間に位置するものを何というでしょう?\n",
    "    - A：医薬部外品\n",
    "  - Q：新しく開発された薬の安全性や効き目などを調べるため、患者の治療を兼ねて行う試験のことを何試験と言うでしょう?\n",
    "    - A：臨床試験\n",
    "\n",
    "また、/data に入っている、「aio_02_train_formatted.jsonl」を開いてみてください。\n",
    "今回、先頭の1000までしか学習させていませんので、その後ろのデータも質問として利用できます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d14eded1-d752-4078-873e-08d17b442b71",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#　答え：アスピリン\n",
    "data = {\n",
    "    \"instruction\": \"代表的な解熱鎮痛剤のひとつで非ステロイド性抗炎症薬の代名詞とも言うべき医薬品で、ドイツのバイエルが命名し、1899年に商標登録された薬品名は？\",\n",
    "    \"max_new_tokens\": 120,\n",
    "    \"temperature\": 0.3,\n",
    "    \"do_sample\": True,\n",
    "    \"pad_token_id\": 1,\n",
    "    \"bos_token_id\": 0,\n",
    "    \"eos_token_is\": 0,\n",
    "    # \"repetition_penalty\": 1.05,\n",
    "    # \"top_p\": 0.75,\n",
    "    # \"top_k\": 40,\n",
    "    # \"no_repeat_ngram_size\": 2,\n",
    "    \"stop_ids\": [1, 0],\n",
    "}\n",
    "response = predictor_client.predict(\n",
    "    data=data\n",
    ")\n",
    "\n",
    "print(\"答えは「\" + response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "005d756d-44b9-4ddc-8bdf-81426eef24ec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 答え：インフォームドコンセント\n",
    "\n",
    "data = {\n",
    "    \"instruction\": \"「充分な説明に基づく合意」を意味する、医療行為を行うにあたって事前に診療の内容を患者に説明し、了承を得ることを英語で何というでしょう?\",\n",
    "    \"max_new_tokens\": 120,\n",
    "    \"temperature\": 0.3,\n",
    "    \"do_sample\": True,\n",
    "    \"pad_token_id\": 1,\n",
    "    \"bos_token_id\": 0,\n",
    "    \"eos_token_is\": 0,\n",
    "    # \"repetition_penalty\": 1.05,\n",
    "    # \"top_p\": 0.75,\n",
    "    # \"top_k\": 40,\n",
    "    # \"no_repeat_ngram_size\": 2,\n",
    "    \"stop_ids\": [1, 0],\n",
    "}\n",
    "response = predictor_client.predict(\n",
    "    data=data\n",
    ")\n",
    "print(\"答えは「\" + response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae16c211-5f6a-4dc4-bbc3-b8f9b07666a0",
   "metadata": {},
   "source": [
    "## ベンチマーク： Speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1c9ddd3-76ee-4f71-8888-4ae51069a967",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%timeit response = predictor_client.predict(data=data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39737593-7053-4dbb-b39b-112e27d228a1",
   "metadata": {},
   "source": [
    "## エンドポイントを削除 (クリーニング)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82559f16-10f8-4573-91d7-e0b85cb7d0de",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "predictor.delete_model()\n",
    "predictor.delete_endpoint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9cb1af1-31e1-4f75-ab61-23781278b58a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science 2.0)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-west-2:236514542706:image/sagemaker-data-science-38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
