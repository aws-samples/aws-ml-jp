# AWS NEURON JP


[AWS Trainium](https://aws.amazon.com/jp/machine-learning/trainium/)ã€[AWS Inferentia](https://aws.amazon.com/jp/machine-learning/inferentia/) ã¯ã€AWSãŒè¨­è¨ˆã—ãŸæ©Ÿæ¢°å­¦ç¿’ã‚¢ã‚¯ã‚»ãƒ©ãƒ¬ãƒ¼ã‚¿ã§ã€ã‚¯ãƒ©ã‚¦ãƒ‰ã§ä½ã‚³ã‚¹ãƒˆã§ã‚³ã‚¹ãƒˆåŠ¹ç‡ã®é«˜ã„æ©Ÿæ¢°å­¦ç¿’ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã€æ¨è«–ã‚’å¯èƒ½ã«ã—ã¾ã™ã€‚



![Neuron Overview](./neuron-aws-ml-chip.png)


## Amazon EC2 Inf1 ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹

[Amazon ECï¼’ Inf1](https://aws.amazon.com/jp/ec2/instance-types/inf1/) ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã¯ 2019å¹´12æœˆã«ãƒ­ãƒ¼ãƒ³ãƒã—ãŸåˆä»£ AWS Inferentia ã‚’æ­è¼‰ã—ãŸã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã§ã™ã€‚ã“ã‚Œã¾ã§ [Money Forward æ§˜](https://aws.amazon.com/jp/builders-flash/202209/create-large-scale-inference-environment/)ã€[ByteDance æ§˜](https://aws.amazon.com/jp/blogs/news/bytedance-saves-up-to-60-on-inference-costs-while-reducing-latency-and-increasing-throughput-using-aws-inferentia/) ã‚’ã¯ã˜ã‚ã¨ã—ãŸå¤šãã® AWS ã®ãŠå®¢æ§˜ã«æ´»ç”¨é ‚ã„ã¦ã„ã‚‹ã ã‘ã§ã¯ãªãã€[Amazon Alexa](https://aws.amazon.com/jp/blogs/news/majority-of-alexa-now-running-on-faster-more-cost-effective-amazon-ec2-inf1-instances/)ã€[Amazon Search](https://aws.amazon.com/jp/blogs/news/how-amazon-search-reduced-ml-inference-costs-by-85-with-aws-inferentia/)ã€[Amazon Robotics](https://aws.amazon.com/jp/solutions/case-studies/amazon-robotics-case-study/) ã¨ã„ã£ãŸ Amazonã€AWS ãŒæä¾›ã—ã¦ã„ã‚‹ã‚µãƒ¼ãƒ“ã‚¹ã‚’æ”¯ãˆã‚‹ã‚¤ãƒ³ãƒ•ãƒ©ã¨ã—ã¦ã‚‚æ´»ç”¨ã•ã‚Œã¦ã„ã¾ã™ã€‚



## Amazon EC2 Trn1 ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹
[Amazon ECï¼’ Trn1](https://aws.amazon.com/jp/ec2/instance-types/trn1/) ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã¯ã€å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMï¼‰ãªã©ã®ç”Ÿæˆç³» AI ãƒ¢ãƒ‡ãƒ«ã®ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã«ç‰¹åŒ–ã—ãŸ AWS Trainium ã‚’æ­è¼‰ã—ãŸã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã§ã™ã€‚Trn1 ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã¯ã€ä»–ã®åŒç­‰ã® Amazon EC2 ã®ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã¨æ¯”è¼ƒã—ã¦ã€ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã«ã‹ã‹ã‚‹ã‚³ã‚¹ãƒˆã‚’æœ€å¤§ 50% å‰Šæ¸›ã—ã¾ã™ã€‚ AWS Trainium ã§ã¯ç¬¬äºŒä¸–ä»£ã¨ãªã‚‹ [NeuronCore-v2](https://awsdocs-neuron.readthedocs-hosted.com/en/latest/general/arch/neuron-hardware/neuron-core-v2.html) ã‚’æ­è¼‰ã—ã¦ã„ã¾ã™ã€‚


## Amazon EC2 Inf2 ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹
[Amazon ECï¼’ Inf2](https://aws.amazon.com/jp/ec2/instance-types/inf2/) ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã¯ã€ç¬¬ 2 ä¸–ä»£ã® AWS Inferentia ã‚¢ã‚¯ã‚»ãƒ©ãƒ¬ãƒ¼ã‚¿ã§ã‚ã‚‹ AWS Inferentia2 ã‚’æ­è¼‰ã—ã¦ã„ã¾ã™ã€‚Inf1 ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã¨æ¯”è¼ƒã—ã€æœ€å¤§ 3 å€ã®ã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã€æœ€å¤§ 4 å€ã®ã‚¢ã‚¯ã‚»ãƒ©ãƒ¬ãƒ¼ã‚¿ãƒ¼ãƒ¡ãƒ¢ãƒªã€æœ€å¤§ 4 å€ã®ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆã€10 åˆ†ã® 1 ä»¥ä¸‹ã®ä½ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·ãƒ¼ã‚’å®Ÿç¾ã—ã¾ã™ã€‚
AWS Trainium ã¨åŒã˜ä¸–ä»£ã¨ãªã‚‹ NeuronCore-v2 ã‚’æ­è¼‰ã€æ¨è«–ã ã‘ã§ã¯ãªãã€å°è¦æ¨¡ãƒ¢ãƒ‡ãƒ«ã®ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã‚‚å®Ÿè¡Œå¯èƒ½ã§ã™ã€‚


## AWS Neuron
[AWS Neuron](https://aws.amazon.com/jp/machine-learning/neuron/) ã¯ã€€AWS Trainiumã€AWS Inferentia ä¸Šã«æ©Ÿæ¢°å­¦ç¿’ãƒ¯ãƒ¼ã‚¯ãƒ­ãƒ¼ãƒ‰ã‚’å®Ÿè£…ã™ã‚‹æ”¯æ´ã‚’ã™ã‚‹ãŸã‚ã® SDK ã§ã™ã€‚PyTorch ã‚„ TensorFlow ãªã©ã®ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã¨ãƒã‚¤ãƒ†ã‚£ãƒ–ã«çµ±åˆã•ã‚Œã‚‹ãŸã‚ã€æ—¢å­˜ã®ã‚³ãƒ¼ãƒ‰ã‚„ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‚’å¼•ãç¶šãåˆ©ç”¨å¯èƒ½ã§ã™ã€‚
æ©Ÿæ¢°å­¦ç¿’ (ML) ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã‚„ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã€ãƒ¢ãƒ‡ãƒ«ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã€ãƒãƒ¼ãƒ‰ã‚¦ã‚§ã‚¢æœ€é©åŒ–ãªã©ã€ç¾åœ¨ã® Neuron ã®ã‚µãƒãƒ¼ãƒˆã«ã¤ã„ã¦ã¯ã€[AWS Neuron ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ](https://awsdocs-neuron.readthedocs-hosted.com/) ã‚’ã”è¦§ãã ã•ã„ã€‚


## :books: æ—¥æœ¬èªã‚³ãƒ³ãƒ†ãƒ³ãƒ„

* [æ—¥æœ¬èª BERT Base Model Fine-tuning & Deployment on Inferentia2/Trainium](./bertj_finetuning_classification/)
  * æ—¥æœ¬èªBERTãƒ¢ãƒ‡ãƒ«ã‚’ç”¨ã„ã¦ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã¨æ¨è«–ã‚’åŒä¸€ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ä¸Šã§é€šã—ã¦å®Ÿè¡Œ
  * inf2.xlarge ã‚‚ã—ãã¯ trn1.2xlargeä¸Šã§å®Ÿè¡Œå¯èƒ½ï¼ˆã‚ˆã‚Šå¤§ãã„ã‚µã‚¤ã‚ºã®ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã§ã‚‚å®Ÿè¡Œå¯èƒ½ï¼‰
* [ViT Model Fine-tuning & Deployment on Inferentia2/Trainium](./ViT_finetuning_classification/)
  * Vision Transformer (ViT) ãƒ¢ãƒ‡ãƒ«ã‚’ beans ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ä½¿ã£ã¦ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã‹ã‚‰æ¨è«–ã¾ã§åŒä¸€ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ä¸Šã§é€šã—ã¦å®Ÿè¡Œ
  * inf2.xlarge ã‚‚ã—ãã¯ trn1.2xlargeä¸Šã§å®Ÿè¡Œå¯èƒ½ï¼ˆã‚ˆã‚Šå¤§ãã„ã‚µã‚¤ã‚ºã®ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã§ã‚‚å®Ÿè¡Œå¯èƒ½ï¼‰

## :books: ã‚°ãƒ­ãƒ¼ãƒãƒ«ã‚³ãƒ³ãƒ†ãƒ³ãƒ„

* https://awsdocs-neuron.readthedocs-hosted.com/en/latest/general/arch/model-architecture-fit.html
  * AWS Trainiumã€AWS Inferentia ãŒå¯¾å¿œã—ã¦ã„ã‚‹ãƒ¢ãƒ‡ãƒ«ã€å¾—æ„ä¸å¾—æ„ãªãƒ¢ãƒ‡ãƒ«ã«é–¢ã—ã¦ã¯ã“ã¡ã‚‰ã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’ã”å‚ç…§ä¸‹ã•ã„ã€‚
* https://github.com/aws-neuron/aws-neuron-samples/
  * This repository contains samples for AWS Neuron, the software development kit (SDK) that enables machine learning (ML) inference and training workloads on the AWS ML accelerator chips Inferentia and Trainium.
* https://github.com/aws-samples/ml-specialized-hardware
  * In this tutorial you'll learn how to use AWS Trainium and AWS Inferentia with Amazon SageMaker and Hugging Face Optimum Neuron, to optimize your ML workloads
* https://github.com/huggingface/optimum-neuron
  * ğŸ¤— Optimum Neuron is the interface between the ğŸ¤— Transformers library and AWS Accelerators including AWS Trainium and AWS Inferentia. It provides a set of tools enabling easy model loading, training and inference on single- and multi-Accelerator settings for different downstream tasks.


## ğŸ“ æ³¨ç›®ã‚³ãƒ³ãƒ†ãƒ³ãƒ„

* Llama2 7B (å­¦ç¿’)
  * [Llama2 pretraining job using neuronx-nemo-megatron](https://github.com/aws-neuron/aws-neuron-parallelcluster-samples/blob/master/examples/jobs/neuronx-nemo-megatron-llamav2-job.md)
* Llama2 7B/13B (æ¨è«– - ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆ)
  * [Llama2 autoregressive sampling using transformers-neuronx](https://github.com/aws-neuron/aws-neuron-samples/blob/master/torch-neuronx/transformers-neuronx/inference/meta-llama-2-13b-sampling.ipynb)
* Stable Diffusion (æ¨è«– - ç”»åƒç”Ÿæˆ)
  * AWSãƒ–ãƒ­ã‚°: [AWS Inferentia2 ã§ Stable Diffusion ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’æœ€å¤§åŒ–ã—ã€æ¨è«–ã‚³ã‚¹ãƒˆã‚’å‰Šæ¸›ã™ã‚‹](https://aws.amazon.com/jp/blogs/news/create-high-quality-images-with-stable-diffusion-models-and-deploy-them-cost-efficiently-with-amazon-sagemaker/)
  * [HuggingFace Stable Diffusion 1.5 (512x512)](https://github.com/aws-neuron/aws-neuron-samples/blob/master/torch-neuronx/inference/hf_pretrained_sd15_512_inference.ipynb)
  * [HuggingFace Stable Diffusion 2.1 (512x512)](https://github.com/aws-neuron/aws-neuron-samples/blob/master/torch-neuronx/inference/hf_pretrained_sd2_512_inference.ipynb)
  * [HuggingFace Stable Diffusion 2.1 (768x768)](https://github.com/aws-neuron/aws-neuron-samples/blob/master/torch-neuronx/inference/hf_pretrained_sd2_768_inference.ipynb)
  * [HuggingFace Stable Diffusion XL 1.0 (1024x1024)](https://github.com/aws-neuron/aws-neuron-samples/blob/master/torch-neuronx/inference/hf_pretrained_sdxl_1024_inference.ipynb)
