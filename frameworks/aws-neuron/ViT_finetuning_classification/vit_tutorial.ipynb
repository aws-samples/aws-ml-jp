{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d4718e6d-7761-415a-87a1-8946df7087f2",
   "metadata": {
    "tags": []
   },
   "source": [
    "# ViT Model Fine-tuning & Deployment on Inferentia2/Trainium\n",
    "\n",
    "ViT ãƒ¢ãƒ‡ãƒ«ã¯ã€ãƒ†ã‚­ã‚¹ãƒˆãƒ™ãƒ¼ã‚¹ã®ã‚¿ã‚¹ã‚¯ç”¨ã«è¨­è¨ˆã•ã‚ŒãŸ transformer ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã«åŸºã¥ããƒ“ã‚¸ãƒ¥ã‚¢ãƒ«ãƒ¢ãƒ‡ãƒ«ã§ã™ã€‚\n",
    "\n",
    "ImageNet-21K ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§äº‹å‰å­¦ç¿’ã•ã‚ŒãŸã€€ViT ãƒ¢ãƒ‡ãƒ«ã‚’ã€Beans ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã—ã¾ã™ã€‚\n",
    "ã“ã®ãƒ¢ãƒ‡ãƒ«ã§ã¯ã€æ•°ã‚¨ãƒãƒƒã‚¯å­¦ç¿’ã™ã‚‹ã“ã¨ã§ã€Beans(è‘‰)ã®å¥åº·çŠ¶æ…‹ã‚’3ã¤ã®ã‚«ãƒ†ã‚´ãƒªã«åˆ†é¡ã—ã¦äºˆæ¸¬å¯èƒ½ã§ã™ã€‚ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "362c27b4-1c5f-4295-8b48-ad423283f1b1",
   "metadata": {},
   "source": [
    "## äº‹å‰æº–å‚™\n",
    "æœ¬ notebookã¯ Neuron 2.14.0 ãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚ŒãŸ Amazon EC2 inf2.xlarge ä¸Šã§å‹•ä½œç¢ºèªã—ã¦ã„ã¾ã™ã€‚\n",
    "ï¼ˆã‚ˆã‚Šå¤§ãã„ã‚µã‚¤ã‚ºã® Inf2 ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹åŠã³ Trn1 ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ä¸Šã§ã‚‚å®Ÿè¡Œå¯èƒ½ã§ã™ã€‚ï¼‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "115c03c9-5b62-4cd6-9a93-657a95e337ad",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install -U pip\n",
    "!pip install -U transformers==4.31.0 accelerate evaluate gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3324f68f-1307-4ef4-99c8-b0d2414bbea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip list | grep \"neuron\\|torch\\|transformers\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf201a69-ce0a-493d-86dd-565d2c067a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "!dpkg --list | grep neuron\n",
    "# For Ubuntu Environment. Please use \"yum list installed\" for Amazon Linux Environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d12f43b-ee0c-4bcc-bda7-b62526202391",
   "metadata": {},
   "outputs": [],
   "source": [
    "!sudo rmmod neuron; sudo modprobe neuron"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccde899b-8e68-4cfe-8708-6a586e077082",
   "metadata": {},
   "source": [
    "## Trainer API ã‚’ä½¿ç”¨ã—ãŸ ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ï¼ˆãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ï¼‰å®Ÿè¡Œ\n",
    "Huggin Face ğŸ¤—Transformers ã«ã¯ Trainer ã¨ã„ã†ä¾¿åˆ©ãªã‚¯ãƒ©ã‚¹ãŒã‚ã‚Šã€Torch Neuron ã‹ã‚‰ã‚‚åˆ©ç”¨å¯èƒ½ã§ã™ã€‚ ã“ã“ã§ã¯ Trainer API ã‚’åˆ©ç”¨ã—ã¦ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚’å®Ÿè¡Œã—ã¦ã„ãã¾ã™ã€‚\n",
    "\n",
    "Neuron SDK ã§ã¯ã€€Huggin Face ğŸ¤—Transformers ä¸Šã®`run_image_classification.py`ã‚¹ã‚¯ãƒªãƒ—ãƒˆã‚’ å¤‰æ›´ã›ãšã«ãã®ã¾ã¾é©ç”¨å¯èƒ½ãªã®ã§ã€ã‚ã‚‰ã‹ã˜ã‚ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã¾ã™ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae1e62f5-789c-44d5-8cc4-c2e0e6c34f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://raw.githubusercontent.com/huggingface/transformers/v4.31.0/examples/pytorch/image-classification/run_image_classification.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e4acb85-ec13-446e-ac78-e48472b2d851",
   "metadata": {},
   "source": [
    "`run_image_classification.py` ã‚¹ã‚¯ãƒªãƒ—ãƒˆã®å†…å®¹ã‚’ç¢ºèªã—ã¦ã¿ã¾ã—ã‚‡ã†ã€‚Trainer API ã‚’åˆ©ç”¨ã—ã¦ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚’å®Ÿè¡Œã—ã¦ã„ã‚‹ã“ã¨ãŒç¢ºèªã§ãã¾ã™ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1daf4b96-f36b-4d67-aeee-2bc5d3f160b1",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pygmentize run_image_classification.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8861405a-694d-4018-ae79-abe6c26d5aa5",
   "metadata": {},
   "source": [
    "- Hugging Face ğŸ¤—Transformers ã‚’ä½¿ç”¨ã—ã¦ ViT ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã—ã¾ã™ã€‚\n",
    "- Neuron ã‚³ã‚¢ä¸Šã§å®Ÿè¡Œã•ã‚Œã‚‹ãƒ‡ãƒ¼ã‚¿å‹ã¯ã€ã‚ˆã‚ŠåŠ¹ç‡ã‚’é«˜ã‚ã‚‹ãŸã‚ã« `fp32` ã§ã¯ãªã `bf16` ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚\n",
    "- ã‚³ãƒ³ãƒ‘ã‚¤ãƒ«ã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã‚¢ãƒ¼ãƒ†ã‚£ãƒ•ã‚¡ã‚¯ãƒˆãŒä¿å­˜ã•ã‚Œã‚‹ãƒ¢ãƒ‡ãƒ«ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªï¼ˆ`./compiler_cache`ï¼‰ã‚’æŒ‡å®šã—ã¾ã™ã€‚\n",
    "- PyTorchã® `torchrun` ã‚³ãƒãƒ³ãƒ‰ã‚’ä½¿ç”¨ã—ã¦ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚¸ãƒ§ãƒ–ã‚’èµ·å‹•ã—ã¾ã™ã€‚\n",
    "- AWS Inferentia2 (ã‚‚ã—ãã¯ AWS Trainium) ã‚¢ã‚¯ã‚»ãƒ©ãƒ¬ãƒ¼ã‚¿ãƒãƒƒãƒ—ã‚’ ï¼‘ã¤æ­è¼‰ã—ãŸã€€Inf2.xlarge (ã‚‚ã—ãã¯ Trn1.2xlarge) ä¸Šã§ã®å®Ÿè¡Œã‚’æƒ³å®šã—ã¦ã„ã¾ã™ã€‚å„ãƒãƒƒãƒ—ã¯ ï¼’ ã¤ã® Neuron ã‚³ã‚¢ã‚’æ­è¼‰ã—ã¦ã„ã‚‹ãŸã‚ `num_workers=2` ã¨è¨­å®šã€çµæœã€ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚¸ãƒ§ãƒ–ã¯ 2ã¤ã® Neuron ã‚³ã‚¢ä¸Šã§å®Ÿè¡Œã•ã‚Œã¾ã™ã€‚\n",
    "- ãƒ¢ãƒ‡ãƒ«ã‚’ 10 ã‚¨ãƒãƒƒã‚¯å­¦ç¿’ã—ã€ã‚¨ãƒãƒƒã‚¯ã”ã¨ã«ãƒ¢ãƒ‡ãƒ«ã®ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã‚’ä¿å­˜ã—ã¾ã™ã€‚ä¿å­˜ã§ãã‚‹ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã¯ 1 ã¤ã¾ã§ã§ã™ã€‚ãƒ­ã‚®ãƒ³ã‚°æƒ…å ±ã¯ 10 å›ã”ã¨ã«å‡ºåŠ›ã—ã¾ã™ã€‚\n",
    "-ã€€`./output` ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«ã¯ã€ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã§ç”Ÿæˆã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã®é‡ã¿ã€Configã€ãã®ä»–ã®ã‚¢ãƒ¼ãƒ†ã‚£ãƒ•ã‚¡ã‚¯ãƒˆãŒæ ¼ç´ã•ã‚Œã¾ã™"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27686c3c-1829-465d-b656-1c399755d401",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "!XLA_USE_BF16=1 NEURON_CC_FLAGS=\"--cache_dir=./compiler_cache\" \\\n",
    "torchrun --nproc_per_node=2 run_image_classification.py \\\n",
    "--model_name_or_path \"google/vit-base-patch16-224-in21k\" \\\n",
    "--dataset_name \"beans\" \\\n",
    "--do_train \\\n",
    "--do_eval \\\n",
    "--num_train_epochs 10 \\\n",
    "--per_device_train_batch_size 16 \\\n",
    "--per_device_eval_batch_size 16 \\\n",
    "--learning_rate 2e-5 \\\n",
    "--logging_strategy steps \\\n",
    "--logging_steps 10 \\\n",
    "--save_strategy epoch \\\n",
    "--save_total_limit 1 \\\n",
    "--seed 1337 \\\n",
    "--remove_unused_columns False \\\n",
    "--overwrite_output_dir \\\n",
    "--output_dir \"output\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5101401-df06-4a6d-9780-8832b9f28e01",
   "metadata": {},
   "source": [
    "ã‚³ãƒ³ãƒ‘ã‚¤ãƒ«æ™‚é–“ã‚’å«ã‚“ã å­¦ç¿’ã«ã¯ `inf2.xlarge` ä¸Šã§å®Ÿè¡Œã—ãŸå ´åˆã§ 25åˆ†ç¨‹åº¦ã‹ã‹ã‚Šã¾ã™.\n",
    "2åº¦ç›®ä»¥é™ã®å®Ÿè¡Œã§ã¯ã‚³ãƒ³ãƒ‘ã‚¤ãƒ«æ¸ˆã¿ã®ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãŒåˆ©ç”¨å¯èƒ½ãªãŸã‚ã€1\\~2åˆ†ç¨‹åº¦ã§å­¦ç¿’ãŒå®Œäº†ã—ã¾ã™ã€‚\n",
    "\n",
    "`neuron_parallel_compile` ã‚³ãƒãƒ³ãƒ‰ã‚’åˆ©ç”¨ã—ãŸã‚³ãƒ³ãƒ‘ã‚¤ãƒ«æ™‚é–“ã®å‰Šæ¸›æ–¹æ³•ã«ã¤ã„ã¦ã¯ã€[æ—¥æœ¬èªBERTãƒ¢ãƒ‡ãƒ«ã®ã‚µãƒ³ãƒ—ãƒ«](https://github.com/AWShtokoyo/aws-ml-jp/tree/main/frameworks/aws-neuron-jp/bertj_finetuning_classification)ã‚’å‚ç…§ä¸‹ã•ã„ã€‚\n",
    "\n",
    "\n",
    "ã“ã‚Œã§ã€€AWS Inferentia2 (AWS Trainium) ä¸Šã§ã® ViT ãƒ¢ãƒ‡ãƒ«ã®ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã«æˆåŠŸã—ã¾ã—ãŸã€‚ \n",
    "`pytorch_model.bin` ã¨ã„ã†åå‰ã®ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã•ã‚ŒãŸé‡ã¿ã‚’æŒã¤ãƒ¢ãƒ‡ãƒ«ã€`Trainer` ã®çŠ¶æ…‹ã€ãƒ¢ãƒ‡ãƒ«è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆ`config.json`ï¼‰ ã‚’å«ã‚€ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒªã‚¹ãƒˆãŒè¡¨ç¤ºã•ã‚Œã¾ã™ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9a484cc-a790-4544-ae04-793ea288c16a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls -l ./output/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca27169e-de1c-438e-b095-089dca381925",
   "metadata": {},
   "source": [
    "# ViT æ¨è«–"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba773524-55dd-4999-a42d-41deec2e9077",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import requests\n",
    "import torch\n",
    "import torch_neuronx\n",
    "from transformers import ViTImageProcessor, ViTForImageClassification\n",
    "\n",
    "# Create the feature extractor and model\n",
    "checkpoint_dir = './output/'\n",
    "print(f\"Create model from provided checkpoint: {checkpoint_dir}\")\n",
    "feature_extractor = ViTImageProcessor.from_pretrained(checkpoint_dir)\n",
    "model = ViTForImageClassification.from_pretrained(checkpoint_dir, torchscript=True)\n",
    "model.eval()\n",
    "\n",
    "# Get an example input\n",
    "url = \"https://datasets-server.huggingface.co/assets/beans/--/default/test/0/image/image.jpg\"\n",
    "image = Image.open(requests.get(url, stream=True).raw)\n",
    "inputs = feature_extractor(images=image, return_tensors=\"pt\")\n",
    "example = (inputs['pixel_values'],)\n",
    "\n",
    "# Run inference on CPU\n",
    "output_cpu = model(*example)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f6950e6-7e4d-40a5-84d0-fd65e6265f15",
   "metadata": {},
   "source": [
    "## æ¨è«–å®Ÿè¡Œã®ãŸã‚ã®ãƒ¢ãƒ‡ãƒ«ã®äº‹å‰ã‚³ãƒ³ãƒ‘ã‚¤ãƒ«\n",
    "\n",
    "æ¨è«–ã‚’ AWS Inferentia2 (ã‚‚ã—ãã¯ AWS Trainium) ä¸Šã§å®Ÿè¡Œã™ã‚‹ãŸã‚ã«ã¯ã€ãƒ¢ãƒ‡ãƒ«ã‚’`torch_neuronx.trace` APIã‚’ç”¨ã„ã¦äº‹å‰ã«ãƒˆãƒ¬ãƒ¼ã‚¹ï¼ˆã‚³ãƒ³ãƒ‘ã‚¤ãƒ«ï¼‰ã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚ãƒˆãƒ¬ãƒ¼ã‚¹ï¼ˆã‚³ãƒ³ãƒ‘ã‚¤ãƒ«ï¼‰ã—ãŸçµæœã¯ä¿å­˜ã™ã‚‹ã“ã¨ã§ãƒ‡ãƒ—ãƒ­ã‚¤æ™‚ã«å†åˆ©ç”¨å¯èƒ½ã§ã™ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "936134c6-12bb-426f-9316-1f6b9e09bbad",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# Compile the model for neuron\n",
    "print(f\"Compile model for neuron with torch tracing ...\")\n",
    "model_neuron = torch_neuronx.trace(model, example)\n",
    "\n",
    "# Save the TorchScript for inference deployment\n",
    "filename = 'vit-model-neuron.pt'\n",
    "torch.jit.save(model_neuron, filename)\n",
    "print(f\"Save compiled model as: {filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bac19f68-ebe6-464a-937f-1bbcb9b9b076",
   "metadata": {},
   "source": [
    "æœŸå¾…é€šã‚Šã®å‡ºåŠ›ãŒå¾—ã‚‰ã‚Œã‚‹ã‹ã©ã†ã‹ã€€CPUä¸Šã§ã®æ¨è«–çµæœã¨æ¯”è¼ƒã—ã¾ã™ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8658aef-2c36-4d1d-bdd5-13bb38db0be8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load the TorchScript compiled model\n",
    "print(f\"Load compiled model: {filename}\")\n",
    "model_neuron = torch.jit.load(filename)\n",
    "\n",
    "# Run inference using the Neuron model\n",
    "print(f\"Run inference on the test image: {url}\")\n",
    "output_neuron = model_neuron(*example)\n",
    "\n",
    "# Compare the results\n",
    "print(f\"--- Compare Neuron output against CPU output ----\")\n",
    "print(f\"CPU tensor:            {output_cpu[0][0][0:10]}\")\n",
    "print(f\"Neuron tensor:         {output_neuron[0][0][0:10]}\")\n",
    "print(f\"CPU prediction:    {model.config.id2label[output_cpu[0].argmax(-1).item()]}\")\n",
    "print(f\"Neuron prediction: {model.config.id2label[output_neuron[0].argmax(-1).item()]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36bfaae7-da47-458b-b6fa-023e2e5a06f8",
   "metadata": {},
   "source": [
    "## Gradio API ã‚’ç”¨ã„ãŸæ¨è«–ãƒ‡ãƒ¢\n",
    "\n",
    "ãƒ¢ãƒ‡ãƒ«ã‚µãƒ¼ãƒ“ã‚¹ã®ãƒ‡ãƒ¢ã‚’ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ã™ã‚‹ç°¡æ˜“ãªæ–¹æ³•ã¯ã€Gradio API ã‚’ä½¿ç”¨ã™ã‚‹ã“ã¨ã§ã™ã€‚ç”»åƒã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãƒ¢ãƒ‡ãƒ«ã«ä¸ãˆã€æ¨è«–çµæœã‚’ç¢ºèªã—ã¾ã™ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64a024e5-b244-488f-9bee-7d7b74a59f5b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "from torchvision.transforms import (\n",
    "    CenterCrop,\n",
    "    Compose,\n",
    "    Normalize,\n",
    "    RandomHorizontalFlip,\n",
    "    RandomResizedCrop,\n",
    "    Resize,\n",
    "    ToTensor,\n",
    ")\n",
    "\n",
    "id2label = {0: 'angular_leaf_spotã€€(è§’è‘‰ã‚¹ãƒãƒƒãƒˆ)', 1: 'bean_rustã€€(è±†ã•ã³ç—…)', 2: 'healthyã€€(å¥åº·)'}\n",
    "\n",
    "def predict(raw_image):\n",
    "    size = (224, 224)\n",
    "    image_mean = [0.5, 0.5, 0.5]\n",
    "    image_std = [0.5, 0.5, 0.5]\n",
    "    normalize = Normalize(mean=image_mean, std=image_std)\n",
    "    \n",
    "    _val_transforms = Compose(\n",
    "        [\n",
    "            Resize(size),\n",
    "            CenterCrop(size),\n",
    "            ToTensor(),\n",
    "            normalize,\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    transformed_image = _val_transforms(raw_image.convert(\"RGB\"))\n",
    "    batched_transformed_image = transformed_image.unsqueeze(0)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        prediction = model_neuron(batched_transformed_image)\n",
    "        pred = id2label[prediction[0].argmax(-1).item()]\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7a1f39d-d001-46d1-a2cf-a19edcad9a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "\n",
    "demo = gr.Interface(fn=predict,\n",
    "             inputs=gr.Image(type=\"pil\"),\n",
    "             outputs=\"text\",\n",
    "             examples=[\n",
    "                 'image_samples/healthy_test.21.jpg',\n",
    "                 'image_samples/angular_leaf_spot_test.21.jpg',\n",
    "                 'image_samples/bean_rust_test.34.jpg'])\n",
    "\n",
    "demo.launch(share=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
