# AWS NEURON JP


[AWS Trainium](https://aws.amazon.com/jp/machine-learning/trainium/)ã€[AWS Inferentia](https://aws.amazon.com/jp/machine-learning/inferentia/) ã¯ã€AWSãŒè¨­è¨ˆã—ãŸæ©Ÿæ¢°å­¦ç¿’ã‚¢ã‚¯ã‚»ãƒ©ãƒ¬ãƒ¼ã‚¿ãƒ¼ã§ã€ã‚¯ãƒ©ã‚¦ãƒ‰ã§ä½ã‚³ã‚¹ãƒˆã§ã‚³ã‚¹ãƒˆåŠ¹ç‡ã®é«˜ã„æ©Ÿæ¢°å­¦ç¿’ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã€æ¨è«–ã‚’å¯èƒ½ã«ã—ã¾ã™ã€‚



![Neuron Overview](./neuron-aws-ml-chips.png)


## Amazon EC2 Inf1 ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹

[Amazon ECï¼’ Inf1](https://aws.amazon.com/jp/ec2/instance-types/inf1/) ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã¯ 2019å¹´12æœˆã«ãƒ­ãƒ¼ãƒ³ãƒã—ãŸåˆä»£ AWS Inferentia ã‚’æ­è¼‰ã—ãŸã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã§ã™ã€‚ã“ã‚Œã¾ã§ [Money Forward æ§˜](https://aws.amazon.com/jp/builders-flash/202209/create-large-scale-inference-environment/)ã€[ByteDance æ§˜](https://aws.amazon.com/jp/blogs/news/bytedance-saves-up-to-60-on-inference-costs-while-reducing-latency-and-increasing-throughput-using-aws-inferentia/) ã‚’ã¯ã˜ã‚ã¨ã—ãŸå¤šãã® AWS ã®ãŠå®¢æ§˜ã«æ´»ç”¨é ‚ã„ã¦ã„ã‚‹ã ã‘ã§ã¯ãªãã€[Amazon Alexa](https://aws.amazon.com/jp/blogs/news/majority-of-alexa-now-running-on-faster-more-cost-effective-amazon-ec2-inf1-instances/)ã€[Amazon Search](https://aws.amazon.com/jp/blogs/news/how-amazon-search-reduced-ml-inference-costs-by-85-with-aws-inferentia/)ã€[Amazon Robotics](https://aws.amazon.com/jp/solutions/case-studies/amazon-robotics-case-study/) ã¨ã„ã£ãŸ Amazonã€AWS ãŒæä¾›ã—ã¦ã„ã‚‹ã‚µãƒ¼ãƒ“ã‚¹ã‚’æ”¯ãˆã‚‹ã‚¤ãƒ³ãƒ•ãƒ©ã¨ã—ã¦ã‚‚æ´»ç”¨ã•ã‚Œã¦ã„ã¾ã™ã€‚



## Amazon EC2 Trn1 ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹
[Amazon ECï¼’ Trn1](https://aws.amazon.com/jp/ec2/instance-types/trn1/) ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã¯ã€å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMï¼‰ãªã©ã®ç”Ÿæˆç³» AI ãƒ¢ãƒ‡ãƒ«ã®ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã«ç‰¹åŒ–ã—ãŸ AWS Trainium ã‚’æ­è¼‰ã—ãŸã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã§ã™ã€‚Trn1 ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã¯ã€ä»–ã®åŒç­‰ã® Amazon EC2 ã®ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã¨æ¯”è¼ƒã—ã¦ã€ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã«ã‹ã‹ã‚‹ã‚³ã‚¹ãƒˆã‚’æœ€å¤§ 50% å‰Šæ¸›ã—ã¾ã™ã€‚ AWS Trainium ã§ã¯ç¬¬äºŒä¸–ä»£ã¨ãªã‚‹ [NeuronCore-v2](https://awsdocs-neuron.readthedocs-hosted.com/en/latest/general/arch/neuron-hardware/neuron-core-v2.html) ã‚’æ­è¼‰ã—ã¦ã„ã¾ã™ã€‚


## Amazon EC2 Inf2 ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹
[Amazon ECï¼’ Inf2](https://aws.amazon.com/jp/ec2/instance-types/inf2/) ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã¯ã€ç¬¬ 2 ä¸–ä»£ã® AWS Inferentia ã‚¢ã‚¯ã‚»ãƒ©ãƒ¬ãƒ¼ã‚¿ãƒ¼ã§ã‚ã‚‹ AWS Inferentia2 ã‚’æ­è¼‰ã—ã¦ã„ã¾ã™ã€‚Inf1 ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã¨æ¯”è¼ƒã—ã€æœ€å¤§ 3 å€ã®ã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã€æœ€å¤§ 4 å€ã®ã‚¢ã‚¯ã‚»ãƒ©ãƒ¬ãƒ¼ã‚¿ãƒ¼ãƒ¡ãƒ¢ãƒªã€æœ€å¤§ 4 å€ã®ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆã€10 åˆ†ã® 1 ä»¥ä¸‹ã®ä½ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·ãƒ¼ã‚’å®Ÿç¾ã—ã¾ã™ã€‚
AWS Trainium ã¨åŒã˜ä¸–ä»£ã¨ãªã‚‹ NeuronCore-v2 ã‚’æ­è¼‰ã€æ¨è«–ã ã‘ã§ã¯ãªãã€å°è¦æ¨¡ãƒ¢ãƒ‡ãƒ«ã®ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã‚‚å®Ÿè¡Œå¯èƒ½ã§ã™ã€‚


## AWS Neuron
[AWS Neuron](https://aws.amazon.com/jp/machine-learning/neuron/) ã¯ã€€AWS Trainiumã€AWS Inferentia ä¸Šã«æ©Ÿæ¢°å­¦ç¿’ãƒ¯ãƒ¼ã‚¯ãƒ­ãƒ¼ãƒ‰ã‚’å®Ÿè£…ã™ã‚‹æ”¯æ´ã‚’ã™ã‚‹ãŸã‚ã® SDK ã§ã™ã€‚PyTorch ã‚„ TensorFlow ãªã©ã®ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã¨ãƒã‚¤ãƒ†ã‚£ãƒ–ã«çµ±åˆã•ã‚Œã‚‹ãŸã‚ã€æ—¢å­˜ã®ã‚³ãƒ¼ãƒ‰ã‚„ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‚’å¼•ãç¶šãåˆ©ç”¨å¯èƒ½ã§ã™ã€‚
æ©Ÿæ¢°å­¦ç¿’ (ML) ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã‚„ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã€ãƒ¢ãƒ‡ãƒ«ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã€ãƒãƒ¼ãƒ‰ã‚¦ã‚§ã‚¢æœ€é©åŒ–ãªã©ã€ç¾åœ¨ã® Neuron ã®ã‚µãƒãƒ¼ãƒˆã«ã¤ã„ã¦ã¯ã€[AWS Neuron ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ](https://awsdocs-neuron.readthedocs-hosted.com/) ã‚’ã”è¦§ãã ã•ã„ã€‚


## :books: æ—¥æœ¬èªã‚³ãƒ³ãƒ†ãƒ³ãƒ„

* [æ—¥æœ¬èª BERT Base Model Fine-tuning & Deployment on Inferentia2/Trainium](./bertj_finetuning_classification/)
  * æ—¥æœ¬èªBERTãƒ¢ãƒ‡ãƒ«ã‚’ç”¨ã„ã¦ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã¨æ¨è«–ã‚’åŒä¸€ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ä¸Šã§é€šã—ã¦å®Ÿè¡Œ
  * inf2.xlarge ã‚‚ã—ãã¯ trn1.2xlargeä¸Šã§å®Ÿè¡Œå¯èƒ½ï¼ˆã‚ˆã‚Šå¤§ãã„ã‚µã‚¤ã‚ºã®ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã§ã‚‚å®Ÿè¡Œå¯èƒ½ï¼‰
* [ViT Model Fine-tuning & Deployment on Inferentia2/Trainium](./ViT_finetuning_classification/)
  * Vision Transformer (ViT) ãƒ¢ãƒ‡ãƒ«ã‚’ beans ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ä½¿ã£ã¦ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã‹ã‚‰æ¨è«–ã¾ã§åŒä¸€ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ä¸Šã§é€šã—ã¦å®Ÿè¡Œ
  * inf2.xlarge ã‚‚ã—ãã¯ trn1.2xlargeä¸Šã§å®Ÿè¡Œå¯èƒ½ï¼ˆã‚ˆã‚Šå¤§ãã„ã‚µã‚¤ã‚ºã®ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã§ã‚‚å®Ÿè¡Œå¯èƒ½ï¼‰

> [!NOTE]
> ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã¯ Jupyter Nodebook å½¢å¼ã§æä¾›ã—ã¦ã„ã¾ã™ã€‚Jupter Notebook ç’°å¢ƒã®ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—æ–¹æ³•ã¯[ã“ã¡ã‚‰](https://awsdocs-neuron.readthedocs-hosted.com/en/latest/general/setup/notebook/setup-jupyter-notebook-steps-troubleshooting.html)ã‚’ã”å‚ç…§ä¸‹ã•ã„ã€‚


## :books: ã‚°ãƒ­ãƒ¼ãƒãƒ«ã‚³ãƒ³ãƒ†ãƒ³ãƒ„

* https://github.com/aws-neuron/aws-neuron-samples/
  * ã“ã®ãƒªãƒã‚¸ãƒˆãƒªã§ã¯ã€AWS MLã‚¢ã‚¯ã‚»ãƒ©ãƒ¬ãƒ¼ã‚¿ãƒ¼ãƒãƒƒãƒ— Inferentia ã¨ Trainium ä¸Šã§æ©Ÿæ¢°å­¦ç¿’æ¨è«–ã¨ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ¯ãƒ¼ã‚¯ãƒ­ãƒ¼ãƒ‰ã‚’å®Ÿè¡Œã™ã‚‹ AWS Neuron ã®ã‚µãƒ³ãƒ—ãƒ«ã‚¹ã‚¯ãƒªãƒ—ãƒˆï¼ˆNodebookï¼‰ã‚’æä¾›ã—ã¦ã„ã¾ã™ã€‚
* https://github.com/aws-samples/ml-specialized-hardware
  * ã“ã®ãƒ¯ãƒ¼ã‚¯ã‚·ãƒ§ãƒƒãƒ—ã§ã¯ã€AWS Trainium ã¨ AWS Inferentia ã‚’ Amazon SageMaker ã¨ Hugging Face Optimum Neuron ã¨ä¸€ç·’ã«ä½¿ç”¨ã—ã¦ ML ãƒ¯ãƒ¼ã‚¯ãƒ­ãƒ¼ãƒ‰ã‚’æœ€é©åŒ–ã™ã‚‹æ–¹æ³•ã‚’å­¦ã³ã¾ã™ã€‚
* https://github.com/huggingface/optimum-neuron
  * ğŸ¤— Optimum Neuron ã¯ã€Hugging Face ãŒæä¾›ã™ã‚‹ ğŸ¤— Transformers ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã¨ AWS Trainium ã‚„ AWS Inferentia ãªã©ã® AWS ã‚¢ã‚¯ã‚»ãƒ©ãƒ¬ãƒ¼ã‚¿ãƒ¼ã¨ã®é–“ã®ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ã§ã™ã€‚ã•ã¾ã–ã¾ãªãƒ€ã‚¦ãƒ³ã‚¹ãƒˆãƒªãƒ¼ãƒ ã‚¿ã‚¹ã‚¯ã«å¯¾ã—ã¦ã‚·ãƒ³ã‚°ãƒ«åŠã³ãƒãƒ«ãƒã‚¢ã‚¯ã‚»ãƒ©ãƒ¬ãƒ¼ã‚¿ãƒ¼ã‚’ç”¨ã„ãŸã€ãƒ¢ãƒ‡ãƒ«ã®èª­ã¿è¾¼ã¿ã€ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã€æ¨è«–ã‚’ç°¡å˜ã«è¡Œã†ãŸã‚ã®ãƒ„ãƒ¼ãƒ«ã‚»ãƒƒãƒˆã‚’ç”¨æ„ã—ã¦ã„ã¾ã™ã€‚æ¤œè¨¼ã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã¨ã‚¿ã‚¹ã‚¯ã®ãƒªã‚¹ãƒˆã¯ã€[ã“ã¡ã‚‰ã‹ã‚‰](https://huggingface.co/docs/optimum-neuron/package_reference/configuration#supported-architectures)ã”è¦§ã„ãŸã ã‘ã¾ã™ã€‚ã¾ãŸå„ç¨®ãƒãƒ¥ãƒ¼ãƒˆãƒªã‚¢ãƒ«ã‚’ç”¨æ„ã—ã¦ã„ã¾ã™ã€‚
  * [Create your own chatbot with llama-2-13B on AWS Inferentia](https://huggingface.co/docs/optimum-neuron/tutorials/llama2-13b-chatbot)
  * [Generate images with Stable Diffusion models on AWS Inferentia](https://huggingface.co/docs/optimum-neuron/tutorials/stable_diffusion)
  * [Fine-tune and Test Llama 2 7B on AWS Trainium](https://huggingface.co/docs/optimum-neuron/tutorials/fine_tune_llama_7b)
  * [Fine-tune BERT for Text Classification on AWS Trainium](https://huggingface.co/docs/optimum-neuron/tutorials/fine_tune_bert)


## ğŸ§‘â€ğŸ¤â€ğŸ§‘ æ´»ç”¨äº‹ä¾‹

2023å¹´7æœˆã«é–‹å§‹ã—ãŸã€Œ[AWS LLM é–‹ç™ºæ”¯æ´ãƒ—ãƒ­ã‚°ãƒ©ãƒ ](https://aws.amazon.com/jp/local/llm-development-support-program/)ã€ã§ã¯ã€åŸºç›¤ãƒ¢ãƒ‡ãƒ«é–‹ç™ºã«æŒ‘ã‚€ 17 ç¤¾ã‚’æ¡æŠã€ãã®ã†ã¡ã®å¤šããŒ AWS Trainium (Amazon EC2 Trn1 ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ï¼‰ã‚’æ´»ç”¨ã—ã¦ãƒ¢ãƒ‡ãƒ«ã®é–‹ç™ºã‚’è¡Œã„ã¾ã—ãŸã€‚

é–¢é€£è¨˜äº‹

* 2024/02/06 (MONOist) [ãƒªã‚³ãƒ¼ãŒ130å„„ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒ¼ã®æ—¥è‹±å¯¾å¿œLLMé–‹ç™º AWSã‚¸ãƒ£ãƒ‘ãƒ³ã®æ”¯æ´ãƒ—ãƒ­ã‚°ãƒ©ãƒ æ´»ç”¨](https://monoist.itmedia.co.jp/mn/articles/2402/06/news075.html)
* 2024/02/01 (EnterpriseZine) [ã€Œä»Šå¹´ã¯ç”ŸæˆAIã®ç¤¾ä¼šå®Ÿè£…ã®å¹´ã«ã€ã¨çµŒç”£çœã€AWS LLMé–‹ç™ºæ”¯æ´ãƒ—ãƒ­ã‚°ãƒ©ãƒ ã®æˆæœç™ºè¡¨ä¼šã§](https://enterprisezine.jp/news/detail/19146)

å‚åŠ ä¼æ¥­ã‹ã‚‰ã®PRã€æŠ€è¡“ãƒ–ãƒ­ã‚°

* 2024/02/02 (Watashihaæ§˜) inf2ç”¨æ¨è«–ã‚¹ã‚¯ãƒªãƒ—ãƒˆãŠã‚ˆã³ã‚³ãƒ³ãƒ‘ã‚¤ãƒ«æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã‚’å…¬é–‹ï¼ˆå…¬é–‹ãƒ¢ãƒ‡ãƒ« [Watashiha-Llama-2-13B-Ogiri-sft-neuron](https://huggingface.co/watashiha/Watashiha-Llama-2-13B-Ogiri-sft-neuron))
* 2024/01/31 (RICOHæ§˜) [æ—¥æœ¬èªç²¾åº¦ãŒé«˜ã„130å„„ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMï¼‰ã‚’é–‹ç™º](https://jp.ricoh.com/release/2024/0131_1)
* 2024/01/31 (ã‚«ãƒ©ã‚¯ãƒªæ§˜) [ã‚«ãƒ©ã‚¯ãƒªã€700å„„ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒ¼LLMã€ŒKARAKURI LMã€ã‚’ä¸€èˆ¬å…¬é–‹](https://karakuri.ai/seminar/news/karakuri-lm/) (å…¬é–‹ãƒ¢ãƒ‡ãƒ« [karakuri-lm-70b-v0.1](https://huggingface.co/karakuri-ai/karakuri-lm-70b-v0.1) / [karakuri-lm-70b-chat-v0.1](https://huggingface.co/karakuri-ai/karakuri-lm-70b-chat-v0.1))
* 2024/01/25 (Watashihaæ§˜) Llama2-13bã«æ—¥æœ¬èªèªå½™ã‚’è¿½åŠ ã—ã¦ç¶™ç¶šäº‹å‰å­¦ç¿’ã‚’è¡Œã£ãŸå¤§å–œåˆ©è¨€èªãƒ¢ãƒ‡ãƒ«ã‚’å…¬é–‹ (å…¬é–‹ãƒ¢ãƒ‡ãƒ« [Watashiha-Llama-2-13B-Ogiri-sft](https://huggingface.co/watashiha/Watashiha-Llama-2-13B-Ogiri-sft))
* 2024/01/25 (ã‚«ãƒ©ã‚¯ãƒªæ§˜) [ã‚«ãƒ©ã‚¯ãƒªã®700å„„ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒ¼LLMã€å›½ç”£ãƒ¢ãƒ‡ãƒ«ã®ä¸­ã§æœ€é«˜æ€§èƒ½ã‚’ç²å¾—](https://karakuri.ai/seminar/news/aws_llm-2/)
* 2024/01/21 (Stockmarkæ§˜) Inf2ç”¨æ¨è«–ã‚¹ã‚¯ãƒªãƒ—ãƒˆã‚’å…¬é–‹ ([inferentia2.ipynb](https://huggingface.co/stockmark/stockmark-13b/blob/main/notebooks/inferentia2.ipynb))
* 2023/12/21 (rinnaæ§˜) [rinnaã€Qwenã®æ—¥æœ¬èªç¶™ç¶šäº‹å‰å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã€ŒNekomataã€ã‚·ãƒªãƒ¼ã‚ºã‚’å…¬é–‹](https://rinna.co.jp/news/2023/12/20231221.html) (å…¬é–‹ãƒ¢ãƒ‡ãƒ« [nekomata-14b](https://huggingface.co/rinna/nekomata-14b))
* 2023/10/26 (Stockmarkæ§˜) [ãƒ“ã‚¸ãƒã‚¹ã®ãƒ‰ãƒ¡ã‚¤ãƒ³ã‚„æœ€æ–°æƒ…å ±ã«å¯¾å¿œã—ãŸ130å„„ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®æ—¥æœ¬èªLLMã®å…¬é–‹](https://tech.stockmark.co.jp/blog/202310_stockmark_13b/) (å…¬é–‹ãƒ¢ãƒ‡ãƒ« [stockmark-13b](https://huggingface.co/stockmark/stockmark-13b))


## ğŸ“ æ³¨ç›®ã‚³ãƒ³ãƒ†ãƒ³ãƒ„

* Llama2
  * AWSãƒ–ãƒ­ã‚°: [AWS Inferentia ã¨ AWS Trainium ã‚’ç”¨ã„ãŸã€AWS SageMaker JumpStart ã«ã‚ˆã‚‹ã‚³ã‚¹ãƒˆæœ€é©åŒ–ã•ã‚ŒãŸ Llama 2 ãƒ¢ãƒ‡ãƒ«ã®ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã¨ãƒ‡ãƒ—ãƒ­ã‚¤](https://aws.amazon.com/jp/blogs/news/fine-tune-and-deploy-llama-2-models-cost-effectively-in-amazon-sagemaker-jumpstart-with-aws-inferentia-and-aws-trainium/)
  * [AWS Neuron Reference for NeMo Megatron ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ç”¨ã„ãŸäº‹å‰å­¦ç¿’ãƒãƒ¥ãƒ¼ãƒˆãƒªã‚¢ãƒ«](https://github.com/aws-neuron/aws-neuron-parallelcluster-samples/blob/master/examples/jobs/neuronx-nemo-megatron-llamav2-job.md) 
  * [Neuron Distributed ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ç”¨ã„ãŸäº‹å‰å­¦ç¿’ãƒãƒ¥ãƒ¼ãƒˆãƒªã‚¢ãƒ«](https://awsdocs-neuron.readthedocs-hosted.com/en/latest/libraries/neuronx-distributed/tutorials/training_llama2_tp_pp.html)
  * [æ¨è«– - ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆã‚µãƒ³ãƒ—ãƒ«](https://github.com/aws-neuron/aws-neuron-samples/blob/master/torch-neuronx/transformers-neuronx/inference/meta-llama-2-13b-sampling.ipynb)
  
* Stable Diffusion
  * AWSãƒ–ãƒ­ã‚°: [AWS Inferentia2 ã§ Stable Diffusion ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’æœ€å¤§åŒ–ã—ã€æ¨è«–ã‚³ã‚¹ãƒˆã‚’å‰Šæ¸›ã™ã‚‹](https://aws.amazon.com/jp/blogs/news/create-high-quality-images-with-stable-diffusion-models-and-deploy-them-cost-efficiently-with-amazon-sagemaker/)
  * [HuggingFace Stable Diffusion 1.5 (512x512)](https://github.com/aws-neuron/aws-neuron-samples/blob/master/torch-neuronx/inference/hf_pretrained_sd15_512_inference.ipynb)
  * [HuggingFace Stable Diffusion 2.1 (512x512)](https://github.com/aws-neuron/aws-neuron-samples/blob/master/torch-neuronx/inference/hf_pretrained_sd2_512_inference.ipynb)
  * [HuggingFace Stable Diffusion 2.1 (768x768)](https://github.com/aws-neuron/aws-neuron-samples/blob/master/torch-neuronx/inference/hf_pretrained_sd2_768_inference.ipynb)
  * [HuggingFace Stable Diffusion XL 1.0 (1024x1024)](https://github.com/aws-neuron/aws-neuron-samples/blob/master/torch-neuronx/inference/hf_pretrained_sdxl_base_and_refiner_1024_inference.ipynb)
